# README.md

## 인공신경망과 딥러닝 과제 #3
## 기계정보공학과 24510091 안정민

### 과제 설명

이 과제에서는 Shakespeare 데이터셋을 사용하여 문자 단위 언어 모델을 구축합니다. 구축할 언어 모델은 "many-to-many" 형태의 순환 신경망입니다. 자세한 설명은 [Karpathy의 글](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)의 "Character-Level Language Models" 섹션을 참고하세요.

### 요구 사항

1. 데이터 제공 파이프라인을 직접 작성하세요. `dataset.py` 템플릿에 코드를 작성하세요.
2. `model.py`에서 vanilla RNN과 LSTM 모델을 구현하세요. 모델 성능을 향상시키기 위해 레이어를 쌓는 것도 가능합니다.
3. `main.py`에서 모델을 학습시키는 코드를 작성하세요. 여기서 학습 과정 중 훈련 및 검증 데이터셋의 평균 손실 값을 모니터링해야 합니다.
4. (보고서) 훈련 및 검증 데이터셋에 대한 평균 손실 값을 그래프로 나타내세요. 검증 데이터셋에 대한 손실 값으로 vanilla RNN과 LSTM의 언어 생성 성능을 비교하세요.
5. `generate.py`를 작성하여 학습된 모델로 문자를 생성하세요. 가장 좋은 검증 성능을 보이는 모델을 선택하세요. 다른 시작 문자를 사용하여 각각 최소 100자의 5개 샘플을 생성하세요.
6. (보고서) 소프트맥스 함수의 온도 매개변수 *T*는 다음과 같이 작성할 수 있습니다:
    ```
    y_i = \frac{\exp(z_i / T)}{\sum{\exp(z_i / T)}}  
    ```
   문자를 생성할 때 다른 온도를 시도해보고, 온도가 어떤 차이를 만드는지, 그리고 왜 더 그럴듯한 결과를 생성하는데 도움이 되는지 논의하세요.

### 실행 방법

1. `dataset.py`, `model.py`, `main.py`, `generate.py` 파일을 같은 디렉토리에 저장합니다.
2. `main.py`를 실행하여 모델을 학습시킵니다.
3. 학습이 완료되면, `generate.py`를 실행하여 문자를 생성합니다.
4. 생성된 문자를 확인하고, 보고서에 결과를 포함시킵니다.

### 참고 문헌

- [Karpathy의 글](http://karpathy.github.io/2015/05/21/rnn-effectiveness/): "Character-Level Language Models" 섹션

이 과제에서는 Shakespeare 데이터셋을 사용하여 문자 단위 언어 모델을 구축하고, vanilla RNN과 LSTM의 성능을 비교하며, 다양한 온도로 문자를 생성해보는 경험을 합니다. 이를 통해 언어 모델의 작동 원리를 이해하고, 모델의 성능을 개선하는 방법을 학습할 수 있습니다.
